{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-traitement du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des librairies et configuration des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 15:02:20.589222: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-16 15:02:20.592794: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-16 15:02:20.607443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-16 15:02:20.628836: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-16 15:02:20.634642: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-16 15:02:20.648337: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-16 15:02:21.692402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version de TensorFlow importée : 2.17.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(\"version de TensorFlow importée :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repertoire des donnés brute\n",
    "raw_data_path = \"../../dataset/\"\n",
    "\n",
    "# Repertoire racine des données\n",
    "root = '../../data/'\n",
    "\n",
    "# DB a utiliser\n",
    "db = 'MO/'\n",
    "\n",
    "# Chemins des dossiers LAYERS vers les data\n",
    "LAYER0 = root+'LAYER0/'\n",
    "LAYER1 = root+'LAYER1/'\n",
    "LAYER2 = root+'LAYER2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de l'architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAYER 0 : Données brutes (séléction et webscraping déjà effectuée)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copie des données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/LAYER0/MO/'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree(raw_data_path, LAYER0+db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Générer les données structurés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_id</th>\n",
       "      <th>merged_ids</th>\n",
       "      <th>imgs_files</th>\n",
       "      <th>total_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>1073,113898,11410,114795,115947,117503,118285,...</td>\n",
       "      <td>1073.jpg,113898.jpg,11410.jpg,114795.jpg,11594...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1003017,1106469,1115838,1115839,1125351,113170...</td>\n",
       "      <td>1003017.jpg,1106469.jpg,1115838.jpg,1115839.jp...</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>267</td>\n",
       "      <td>1042116,1051907,1055774,1055775,1055776,105577...</td>\n",
       "      <td>1042116.jpg,1051907.jpg,1055774.jpg,1055775.jp...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330</td>\n",
       "      <td>1000839,101125,101126,1020108,1047060,1058461,...</td>\n",
       "      <td>1000839.jpg,101125.jpg,101126.jpg,1020108.jpg,...</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>344</td>\n",
       "      <td>102050,107133,1071722,1075718,1089687,1090898,...</td>\n",
       "      <td>102050.jpg,107133.jpg,1071722.jpg,1075718.jpg,...</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>362</td>\n",
       "      <td>1001208,1002765,1002766,1002767,1002768,100276...</td>\n",
       "      <td>1001208.jpg,1002765.jpg,1002766.jpg,1002767.jp...</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>373</td>\n",
       "      <td>1017358,1029199,1029201,1029205,1040142,104014...</td>\n",
       "      <td>1017358.jpg,1029199.jpg,1029201.jpg,1029205.jp...</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>382</td>\n",
       "      <td>100599,100600,1047052,1062503,1062531,1069054,...</td>\n",
       "      <td>100599.jpg,100600.jpg,1047052.jpg,1062503.jpg,...</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>401</td>\n",
       "      <td>1027663,1036403,1036404,1036405,103870,107722,...</td>\n",
       "      <td>1027663.jpg,1036403.jpg,1036404.jpg,1036405.jp...</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1174</td>\n",
       "      <td>1038882,1043175,1043176,1061154,1076908,113092...</td>\n",
       "      <td>1038882.jpg,1043175.jpg,1043176.jpg,1061154.jp...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1540</td>\n",
       "      <td>1070158,1072158,1072159,1076350,1076351,108143...</td>\n",
       "      <td>1070158.jpg,1072158.jpg,1072159.jpg,1076350.jp...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2749</td>\n",
       "      <td>1054198,1054199,1054203,1062616,1062619,108355...</td>\n",
       "      <td>1054198.jpg,1054199.jpg,1054203.jpg,1062616.jp...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15162</td>\n",
       "      <td>1044677,1044678,1068730,107367,107368,1075297,...</td>\n",
       "      <td>1044677.jpg,1044678.jpg,1068730.jpg,107367.jpg...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50164</td>\n",
       "      <td>1075389,1075390,1075391,1075392,1081755,108374...</td>\n",
       "      <td>1075389.jpg,1075390.jpg,1075391.jpg,1075392.jp...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>63454</td>\n",
       "      <td>1026987,1026988,1034078,1034079,1177753,117974...</td>\n",
       "      <td>1026987.jpg,1026988.jpg,1034078.jpg,1034079.jp...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29997</td>\n",
       "      <td>1019402,1022171,1022173,1031446,1032006,103200...</td>\n",
       "      <td>1019402.jpg,1022171.jpg,1022173.jpg,1031446.jp...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>623</td>\n",
       "      <td>1007228,1007229,1017474,1019628,1022184,103341...</td>\n",
       "      <td>1007228.jpg,1007229.jpg,1017474.jpg,1019628.jp...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>47721</td>\n",
       "      <td>1004292,1012807,1012808,1012809,1012810,101281...</td>\n",
       "      <td>1004292.jpg,1012807.jpg,1012808.jpg,1012809.jp...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39842</td>\n",
       "      <td>1071341,1074742,1074746,1074764,1085398,108540...</td>\n",
       "      <td>1071341.jpg,1074742.jpg,1074746.jpg,1074764.jp...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4920</td>\n",
       "      <td>1053965,1055903,1056956,1077899,1094292,111095...</td>\n",
       "      <td>1053965.jpg,1055903.jpg,1056956.jpg,1077899.jp...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>939</td>\n",
       "      <td>1035343,1038481,105772,106173,108166,108465,11...</td>\n",
       "      <td>1035343.jpg,1038481.jpg,105772.jpg,106173.jpg,...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>407</td>\n",
       "      <td>1078012,1078013,1084745,1084755,1087800,120292...</td>\n",
       "      <td>1078012.jpg,1078013.jpg,1084745.jpg,1084755.jp...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>271</td>\n",
       "      <td>1060481,1093247,1093248,1093249,1093250,112024...</td>\n",
       "      <td>1060481.jpg,1093247.jpg,1093248.jpg,1093249.jp...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species_id                                         merged_ids  \\\n",
       "0          42  1073,113898,11410,114795,115947,117503,118285,...   \n",
       "1          53  1003017,1106469,1115838,1115839,1125351,113170...   \n",
       "2         267  1042116,1051907,1055774,1055775,1055776,105577...   \n",
       "3         330  1000839,101125,101126,1020108,1047060,1058461,...   \n",
       "4         344  102050,107133,1071722,1075718,1089687,1090898,...   \n",
       "5         362  1001208,1002765,1002766,1002767,1002768,100276...   \n",
       "6         373  1017358,1029199,1029201,1029205,1040142,104014...   \n",
       "7         382  100599,100600,1047052,1062503,1062531,1069054,...   \n",
       "8         401  1027663,1036403,1036404,1036405,103870,107722,...   \n",
       "9        1174  1038882,1043175,1043176,1061154,1076908,113092...   \n",
       "10       1540  1070158,1072158,1072159,1076350,1076351,108143...   \n",
       "11       2749  1054198,1054199,1054203,1062616,1062619,108355...   \n",
       "12      15162  1044677,1044678,1068730,107367,107368,1075297,...   \n",
       "13      50164  1075389,1075390,1075391,1075392,1081755,108374...   \n",
       "14      63454  1026987,1026988,1034078,1034079,1177753,117974...   \n",
       "15      29997  1019402,1022171,1022173,1031446,1032006,103200...   \n",
       "16        623  1007228,1007229,1017474,1019628,1022184,103341...   \n",
       "17      47721  1004292,1012807,1012808,1012809,1012810,101281...   \n",
       "18      39842  1071341,1074742,1074746,1074764,1085398,108540...   \n",
       "19       4920  1053965,1055903,1056956,1077899,1094292,111095...   \n",
       "20        939  1035343,1038481,105772,106173,108166,108465,11...   \n",
       "21        407  1078012,1078013,1084745,1084755,1087800,120292...   \n",
       "22        271  1060481,1093247,1093248,1093249,1093250,112024...   \n",
       "\n",
       "                                           imgs_files  total_files  \n",
       "0   1073.jpg,113898.jpg,11410.jpg,114795.jpg,11594...          246  \n",
       "1   1003017.jpg,1106469.jpg,1115838.jpg,1115839.jp...          192  \n",
       "2   1042116.jpg,1051907.jpg,1055774.jpg,1055775.jp...          203  \n",
       "3   1000839.jpg,101125.jpg,101126.jpg,1020108.jpg,...          190  \n",
       "4   102050.jpg,107133.jpg,1071722.jpg,1075718.jpg,...          194  \n",
       "5   1001208.jpg,1002765.jpg,1002766.jpg,1002767.jp...          201  \n",
       "6   1017358.jpg,1029199.jpg,1029201.jpg,1029205.jp...          249  \n",
       "7   100599.jpg,100600.jpg,1047052.jpg,1062503.jpg,...          236  \n",
       "8   1027663.jpg,1036403.jpg,1036404.jpg,1036405.jp...          164  \n",
       "9   1038882.jpg,1043175.jpg,1043176.jpg,1061154.jp...          226  \n",
       "10  1070158.jpg,1072158.jpg,1072159.jpg,1076350.jp...          153  \n",
       "11  1054198.jpg,1054199.jpg,1054203.jpg,1062616.jp...          103  \n",
       "12  1044677.jpg,1044678.jpg,1068730.jpg,107367.jpg...          144  \n",
       "13  1075389.jpg,1075390.jpg,1075391.jpg,1075392.jp...          105  \n",
       "14  1026987.jpg,1026988.jpg,1034078.jpg,1034079.jp...          105  \n",
       "15  1019402.jpg,1022171.jpg,1022173.jpg,1031446.jp...          120  \n",
       "16  1007228.jpg,1007229.jpg,1017474.jpg,1019628.jp...           82  \n",
       "17  1004292.jpg,1012807.jpg,1012808.jpg,1012809.jp...           87  \n",
       "18  1071341.jpg,1074742.jpg,1074746.jpg,1074764.jp...          103  \n",
       "19  1053965.jpg,1055903.jpg,1056956.jpg,1077899.jp...          144  \n",
       "20  1035343.jpg,1038481.jpg,105772.jpg,106173.jpg,...          135  \n",
       "21  1078012.jpg,1078013.jpg,1084745.jpg,1084755.jp...          147  \n",
       "22  1060481.jpg,1093247.jpg,1093248.jpg,1093249.jp...          136  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de fichiers : 3665\n",
      "Data saved to ../../data/LAYER0/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for id_folder in os.listdir(LAYER0+db):\n",
    "    path = LAYER0+db+id_folder\n",
    "    files = os.listdir(path)\n",
    "    files_without_extension = [os.path.splitext(file)[0] for file in files]  # os.path.splitext(file) : Cette fonction de la bibliothèque os.path prend un nom de fichier et le divise en deux parties\n",
    "    data.append({\n",
    "        \"species_id\": id_folder, \n",
    "        \"merged_ids\": ','.join(files_without_extension),\n",
    "        \"imgs_files\": ','.join(files),\n",
    "        \"total_files\": len(files)\n",
    "    })\n",
    "\n",
    "webscraped = pd.DataFrame(data)\n",
    "display(webscraped)\n",
    "print(\"Nombre total de fichiers :\", webscraped['total_files'].sum())\n",
    "\n",
    "# Génération du fichier CSV\n",
    "webscraped.to_csv(LAYER0+'dataset.csv', index=False) \n",
    "print(f'Data saved to {LAYER0}'+'dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAYER 1 : Transformation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le répertoire de la DB\n",
    "if not os.path.isdir(LAYER1+db):\n",
    "    os.makedirs(LAYER1+db)\n",
    "\n",
    "# Transformation\n",
    "for specie in os.listdir(LAYER0+db):\n",
    "    if not os.path.isdir(LAYER1+db+specie):\n",
    "        os.makedirs(LAYER1+db+specie)\n",
    "    fichiers = os.listdir(LAYER0+db+specie)\n",
    "\n",
    "    for fichier in fichiers:\n",
    "        if not os.path.isfile(LAYER1+db+specie+'/'+fichier):\n",
    "            image = Image.open(LAYER0+db+specie+'/'+fichier)\n",
    "            zone_recadrage = (0, 0, 224, 224) # Taille de l'image\n",
    "            image_recadree = image.crop(zone_recadrage)\n",
    "            image_recadree.save(LAYER1+db+specie+'/'+fichier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAYER 2 : Augmentation des donnés et séparation des donnés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction personalisé pour l'augmentation des donnés et la séparation des donnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentData(\n",
    "        source_path,\n",
    "        dest_path,\n",
    "        train_size_percent,\n",
    "        target_train_size,\n",
    "        max_class_size,\n",
    "        min_class_size,\n",
    "        ):\n",
    "\n",
    "    # Nettoyage de l'arborescence avant de commencer\n",
    "    if os.path.isdir(dest_path):\n",
    "        shutil.rmtree(dest_path)\n",
    "\n",
    "    species = os.listdir(source_path)\n",
    "\n",
    "    # Création des dossiers à partir de la liste dans le DataFrame\n",
    "    for specie in species:\n",
    "        images_source = os.listdir(source_path+\"/\"+str(specie))\n",
    "        if len(images_source) < min_class_size:\n",
    "            continue;\n",
    "        for split_folder in [\"train\", \"validation\", \"test\"]:\n",
    "            folder_path = os.path.join(dest_path, split_folder, specie) # Construire le chemin complet du dossier\n",
    "            os.makedirs(folder_path, exist_ok=True) # Créer le dossier, existe_ok=True permet de ne pas lever d'erreur si le dossier existe déjà\n",
    "\n",
    "\n",
    "    # Configuration des paramètres pour l'augmentation des images\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.Rescaling(1./255),                       # Mise à l'échelle\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),   # Flip\n",
    "        layers.RandomRotation(0.2),                     # Rotation\n",
    "        layers.RandomZoom((-0.2, 0.2)),                 # Zoom\n",
    "        layers.RandomTranslation(0.2, 0.2),             # Translation\n",
    "        layers.RandomBrightness(factor= [-.001, .001]), # Ajustement de la luminosité\n",
    "        layers.RandomContrast(factor= .4),              # Ajustement du contraste\n",
    "    ])\n",
    "\n",
    "    # Data Augmentation\n",
    "    for specie in species: # Pour chaque espèce de champi\n",
    "        images_source = os.listdir(source_path+\"/\"+str(specie))\n",
    "        if len(images_source) < min_class_size:\n",
    "            continue;\n",
    "        \n",
    "        #calcul nb images de l'espèce courrante à mettre dans le jeu de train\n",
    "        if(max_class_size == 0):\n",
    "            train_count = round(len(images_source) * train_size_percent / 100)\n",
    "        else:\n",
    "            train_count = round(max_class_size * train_size_percent / 100)\n",
    "            \n",
    "        train_count_total = 0\n",
    "        source_pictures_count = 0\n",
    "        \n",
    "        for pic in images_source:\n",
    "\n",
    "            if(train_count > 0):\n",
    "                split_dir = \"train\"\n",
    "                train_count_total += 1\n",
    "                #calcul nb images augmentées à générer pour chaque image source\n",
    "                augment_ratio = math.floor( (target_train_size - train_count_total) / train_count)\n",
    "            else:\n",
    "                if(max_class_size == 0 or source_pictures_count < max_class_size):\n",
    "                    split_dir = \"validation\"\n",
    "                else:\n",
    "                    split_dir = \"test\"\n",
    "\n",
    "            # Chemin complet de l'image champi\n",
    "            mushroom_pic_path = str(source_path+\"/\"+str(specie)+\"/\"+str(pic))\n",
    "\n",
    "            # Décodage de l'image JPEG en tant qu'image tensor, channels=3 pour une image couleur (RGB)\n",
    "            image = tf.image.decode_jpeg(tf.io.read_file(mushroom_pic_path), channels=3) \n",
    "\n",
    "            #copie de l'image d'origine dans le dataset\n",
    "            shutil.copy(mushroom_pic_path, str(dest_path)+\"/\"+split_dir+\"/\"+str(specie)+\"/\"+str(pic))\n",
    "\n",
    "            if(train_count > 0):\n",
    "                for i in range(augment_ratio): # Nombre d'images aumgentée générée par photo\n",
    "                    # Générer l'image augmentée\n",
    "                    augmented_image = data_augmentation(image)\n",
    "\n",
    "                    # Enregistrer l'image au format JPEG\n",
    "                    augmented_image_conv = tf.image.convert_image_dtype(augmented_image, tf.uint8) # Convertion\n",
    "                    augmented_image_enc = tf.image.encode_jpeg(augmented_image_conv) # Encodage JPEG\n",
    "                    fname = str(pic)+\"_\"+str(i)+\".jpg\" # Nommage\n",
    "                    with open(str(dest_path)+\"/\"+split_dir+\"/\"+str(specie)+\"/\"+str(fname), 'wb') as f: f.write(augmented_image_enc.numpy()) # Écriture\n",
    "                    train_count_total += 1\n",
    "                    if(train_count_total == target_train_size):\n",
    "                        break\n",
    "            \n",
    "            train_count -= 1\n",
    "            source_pictures_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentData(\n",
    "        source_path = LAYER1+db,\n",
    "        dest_path = LAYER2+db,\n",
    "        train_size_percent = 70,\n",
    "        target_train_size = 1000,\n",
    "        max_class_size = 120, # Nombre de photos conservées, les autres servirons pour le jeu de test\n",
    "        min_class_size = 135, # Les classes ne disposant pas assez d'images seront ignorés\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier trouvés :  3  ( 330.21 Mo ) :\n",
      "\n",
      "train\n",
      "validation\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "def get_total_size(directory):\n",
    "    total_size = 0\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(root, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                filesize = os.path.getsize(filepath)\n",
    "                total_size += filesize\n",
    "    return total_size / 1024 ** 2  # Convertir en Mégaoctets\n",
    "\n",
    "# Liste des dossiers\n",
    "print(\"Dossier trouvés : \", len(os.listdir(LAYER2+db)), \" (\", round(get_total_size(LAYER2+db), 2), \"Mo ) :\\n\")\n",
    "for item in os.listdir(LAYER2+db):\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
